{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "from hashlib import sha256\n",
    "import io\n",
    "import math\n",
    "import collections\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'loomings' already exists\n",
      "'loomings.txt' is successfully uploaded as object 'loomings.txt' to bucket 'loomings'.\n"
     ]
    }
   ],
   "source": [
    "#Connection to my Minio Server which I installed in GCP\n",
    "client = Minio(\n",
    "    \"35.202.171.168:9000\",\n",
    "    access_key=\"minioadmin\",\n",
    "    secret_key=\"minioadmin\",\n",
    "    secure=False\n",
    ")\n",
    "\n",
    "# Make 'loomings' bucket if not exist.\n",
    "found = client.bucket_exists(\"loomings\")\n",
    "if not found:\n",
    "    client.make_bucket(\"loomings\")\n",
    "    print(\"Successfully created bucket 'loomings'\")\n",
    "else:\n",
    "    print(\"Bucket 'loomings' already exists\")\n",
    "    \n",
    "#Push loomings.txt fileto bucket\n",
    "client.fput_object(\"loomings\", \"loomings.txt\", 'loomings.txt')\n",
    "print(\"'loomings.txt' is successfully uploaded as object 'loomings.txt' to bucket 'loomings'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File-1  is successfully uploaded to bucket 'loomings' with metadata  {'Content-hash': '08a2152f1443355617cb16b6b84b206771cdc1a6cecfae86b15bed1715c0dc18'}\n",
      "File-2  is successfully uploaded to bucket 'loomings' with metadata  {'Content-hash': '550f91de362c86e7ab08d3e55b6c2ec6316c85e34285d8b37bb97528f8a709a0'}\n",
      "File-3  is successfully uploaded to bucket 'loomings' with metadata  {'Content-hash': 'a00e0126c2b8b458e7d375c6d8c1c75b1ba1b48f5082cc7f39ad6e57ba736fdd'}\n",
      "File-4  is successfully uploaded to bucket 'loomings' with metadata  {'Content-hash': '555164242460f0b53b95cd82195aaa111dd639fa2ee640b4ce3bb944fb3ba60d'}\n",
      "File-5  is successfully uploaded to bucket 'loomings' with metadata  {'Content-hash': '3878fc5938524787dcc77e5c5d6e6c6d7914389be3dc725ebc633551a2405058'}\n",
      "File-6  is successfully uploaded to bucket 'loomings' with metadata  {'Content-hash': '6c6c8ea443c8b57a28d3fc43bb1a493ae1dcdbda0f851218f621b353186c7a74'}\n",
      "File-7  is successfully uploaded to bucket 'loomings' with metadata  {'Content-hash': '2283e4bb2c5be614691a659b7cffb580ad644641d6b5569b47492a205b01e907'}\n",
      "File-8  is successfully uploaded to bucket 'loomings' with metadata  {'Content-hash': 'e11a73c6f08507124618c610a705fc9a3379c8cbc9c6e61e2e3712ee7fa10b9c'}\n",
      "File-9  is successfully uploaded to bucket 'loomings' with metadata  {'Content-hash': '54fd5e7cc452e1fda3c38a5d35141f77a25b5c114dbe6db4c059812b41d7129a'}\n",
      "File-10  is successfully uploaded to bucket 'loomings' with metadata  {'Content-hash': 'aa2898bbb2a259ddd7f901e2e820069b90cd96eb79d26782b93422c3fca57cf8'}\n",
      "File-11  is successfully uploaded to bucket 'loomings' with metadata  {'Content-hash': 'fb86a0e7a22bdb0f0cc838c8ef266476b6af35fb6dfa4f8d65f33e4f7d732274'}\n",
      "File-12  is successfully uploaded to bucket 'loomings' with metadata  {'Content-hash': 'ac30b1aa2f3e043267f3a27ea2cd17cb06d9c2ed2f6a3a419e6487481dcc6c7a'}\n",
      "File-13  is successfully uploaded to bucket 'loomings' with metadata  {'Content-hash': '733197f1fcf8c698b0420faa82e98309b6681b4d1923a1fc474b3666820670b7'}\n",
      "File-14  is successfully uploaded to bucket 'loomings' with metadata  {'Content-hash': '8d57662d511903e9ad713d1ad5574532df39ccfdb4948835d64476743bfe708d'}\n",
      "File-15  is successfully uploaded to bucket 'loomings' with metadata  {'Content-hash': 'e11a73c6f08507124618c610a705fc9a3379c8cbc9c6e61e2e3712ee7fa10b9c'}\n",
      "File-16  is successfully uploaded to bucket 'loomings' with metadata  {'Content-hash': '8b582ddc18ccf7f20fdbb6ce69a00abe1c9570890b7bc3be3d06b7d7e2386401'}\n",
      "\n",
      "Total number of Non blank lines :  16\n"
     ]
    }
   ],
   "source": [
    "#Read each line from loomings.txt and push each line as a file to the bucket including the metadata\n",
    "with open('loomings.txt', 'r',encoding='utf-8') as loomings:\n",
    "    lines = loomings.readlines()\n",
    "    fileCount = 0\n",
    "    for line in lines:\n",
    "        strippedLine = line.strip()\n",
    "        if(len(strippedLine)>0):\n",
    "            strippedLine = strippedLine.encode('utf-8')\n",
    "            fileCount += 1\n",
    "            filename = \"File-\"+str(fileCount)\n",
    "            #I have used SHA256 to find the hash of the file\n",
    "            hash = sha256(strippedLine).hexdigest()\n",
    "            length = len(strippedLine)\n",
    "                        \n",
    "            #put_object is used to create a file with a string.\n",
    "            client.put_object(\n",
    "                \"loomings\", filename, io.BytesIO(bytes(strippedLine)), length, metadata={\"Content-hash\": hash},\n",
    "            )\n",
    "            print(filename, \" is successfully uploaded to bucket 'loomings' with metadata \", {\"Content-hash\": hash})\n",
    "            \n",
    "\n",
    "#Printing the numbe of non blank lines using the counter variable fileCount\n",
    "print(\"\\nTotal number of Non blank lines : \", str(fileCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of files and their sizes in ascending order:\n",
      "FileName :  File-12,    File Size :  139\n",
      "FileName :  File-16,    File Size :  336\n",
      "FileName :   File-2,    File Size :  389\n",
      "FileName :   File-4,    File Size :  598\n",
      "FileName :   File-5,    File Size :  628\n",
      "FileName :  File-13,    File Size :  659\n",
      "FileName :   File-3,    File Size :  667\n",
      "FileName :  File-10,    File Size :  709\n",
      "FileName :   File-9,    File Size :  783\n",
      "FileName :  File-14,    File Size :  785\n",
      "FileName :  File-15,    File Size :  831\n",
      "FileName :   File-8,    File Size :  831\n",
      "FileName :   File-1,    File Size : 1115\n",
      "FileName :  File-11,    File Size : 1184\n",
      "FileName :   File-7,    File Size : 1452\n",
      "FileName :   File-6,    File Size : 1956\n"
     ]
    }
   ],
   "source": [
    "#Finding the size of all files using list_objects\n",
    "fileSizeMap = []\n",
    "for file in client.list_objects('loomings'):\n",
    "    filename = file.object_name\n",
    "    if('File-' in filename):\n",
    "        fileSizeMap.append([filename, file.size])\n",
    "                \n",
    "#Sorting the list according the size of each file\n",
    "print(\"List of files and their sizes in ascending order:\")\n",
    "fileSizeMap.sort(key=lambda x: x[1])\n",
    "for fileSize in fileSizeMap:\n",
    "    print(\"FileName : \"+fileSize[0].rjust(8)+\",    File Size : \"+str(fileSize[1]).rjust(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File-8, File-15 have the same hash digest.\n",
      "\n",
      "The original text line of File-8:  No, when I go to sea, I go as a simple sailor, right before the mast, plumb down into the forecastle, aloft there to the royal mast-head. True, they rather order me about some, and make me jump from spar to spar, like a grasshopper in a May meadow. And at first, this sort of thing is unpleasant enough. It touches oneâ€™s sense of honor, particularly if you come of an old established family in the land, the Van Rensselaers, or Randolphs, or Hardicanutes. And more than all, if just previous to putting your hand into the tar-pot, you have been lording it as a country schoolmaster, making the tallest boys stand in awe of you. The transition is a keen one, I assure you, from a schoolmaster to a sailor, and requires a strong decoction of Seneca and the Stoics to enable you to grin and bear it. But even this wears off in time.\n",
      "\n",
      "Lines 15 will be removed from 'loomings.txt' as they are duplicates.\n",
      "'loomings-clean.txt' has been generated with unique statements\n"
     ]
    }
   ],
   "source": [
    "#Method to get file content using the fget_object \n",
    "def getFileContent(fileName):\n",
    "    client.fget_object('loomings', fileName, fileName)\n",
    "    with open(fileName, 'r',encoding='utf-8') as file:\n",
    "        line = file.readline().strip()\n",
    "    os.remove(fileName)\n",
    "    return line\n",
    "                \n",
    "#Creating a hashmap with hash as key and list of files as value.\n",
    "hashFilesMap = collections.defaultdict(list)\n",
    "for file in client.list_objects('loomings'):\n",
    "    if('File-' in file.object_name):\n",
    "        fileName = file.object_name\n",
    "        fileInfo = client.fget_object('loomings', fileName, fileName)\n",
    "        hash = fileInfo.metadata['x-amz-meta-content-hash']\n",
    "        os.remove(fileName)\n",
    "        hashFilesMap[hash].insert(0,fileName)\n",
    "    \n",
    "#If there are multiple files with the same hash, then they are duplicates. So just keep one of them. \n",
    "for files in hashFilesMap.values():\n",
    "    if(len(files)>1):\n",
    "        print(', '.join(files), \"have the same hash digest.\")\n",
    "        print(\"\\nThe original text line of \"+files[0]+\": \", getFileContent(files[0]))\n",
    "        \n",
    "#Variable to store the list of line numbers to be deleted as they are duplicates.\n",
    "deleteLines = list()\n",
    "\n",
    "for files in hashFilesMap.values():\n",
    "    if len(files)>1:\n",
    "        deleteLines.extend([x.replace('File-', '') for x in files[1:]])\n",
    "        \n",
    "print(\"\\nLines\", ','.join(deleteLines), \"will be removed from 'loomings.txt' as they are duplicates.\")\n",
    "\n",
    "#Create a new file with all the lines from loomings.txt except for the duplicates\n",
    "with open('loomings.txt', 'r',encoding='utf-8') as loomings:\n",
    "    with open('loomings-clean.txt', 'w', encoding='utf-8') as clean:\n",
    "        clean.truncate(0)\n",
    "        lines = loomings.readlines()\n",
    "        j = 0\n",
    "        for i, line in enumerate(lines):\n",
    "            if(len(line.strip())>0):\n",
    "                j += 1\n",
    "                if(j not in deleteLines):\n",
    "                    clean.write(str(line))\n",
    "                    if(i!=len(lines)-1): clean.write(\"\\n\")\n",
    "print(\"'loomings-clean.txt' has been generated with unique statements\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
